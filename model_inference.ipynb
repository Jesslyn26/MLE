{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50484d2-bfa4-40b6-82cd-e8bf86187cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import model_inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcac9436-de95-4ebf-9655-56df8e1eafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a .py script that takes a snapshot date, loads a model artefact and make an inference and save to datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c91bb1-bcf0-4195-90f3-dc88806ebf8c",
   "metadata": {},
   "source": [
    "## set up pyspark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fb3bc6-4166-4893-88e1-0d3140df5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30206071-5f00-4c3b-be13-55c54db8e336",
   "metadata": {},
   "source": [
    "## set up config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca7d9f0-cfbc-4098-826c-5537ba56b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_date_str = \"2024-01-01\"\n",
    "model_name = \"credit_model_2024_09_02.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75f0bb22-745b-4342-9779-4425795dc752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 1, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-01-01'}\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "config[\"snapshot_date_str\"] = snapshot_date_str\n",
    "config[\"snapshot_date\"] = datetime.strptime(config[\"snapshot_date_str\"], \"%Y-%m-%d\")\n",
    "config[\"model_name\"] = model_name\n",
    "config[\"model_bank_directory\"] = \"model_bank/\"\n",
    "config[\"model_artefact_filepath\"] = config[\"model_bank_directory\"] + config[\"model_name\"]\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8c974-7a80-44ec-a73f-b72c46b70972",
   "metadata": {},
   "source": [
    "## load model artefact from model bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4704571-1729-49ef-b2fb-e7346fc37d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the pickle file\n",
    "with open(config[\"model_artefact_filepath\"], 'rb') as file:\n",
    "    model_artefact = pickle.load(file)\n",
    "\n",
    "print(\"Model loaded successfully! \" + config[\"model_artefact_filepath\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441303bb-1736-4589-8537-c914d8d843b1",
   "metadata": {},
   "source": [
    "## load feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d002feb1-30f5-415a-91ef-b686ee8de99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>fe_1</th>\n",
       "      <th>fe_2</th>\n",
       "      <th>fe_3</th>\n",
       "      <th>fe_4</th>\n",
       "      <th>fe_5</th>\n",
       "      <th>fe_6</th>\n",
       "      <th>fe_7</th>\n",
       "      <th>fe_8</th>\n",
       "      <th>fe_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix_Standard</th>\n",
       "      <th>Loan_Home_Equity_Loan</th>\n",
       "      <th>Loan_Payday_Loan</th>\n",
       "      <th>Loan_Personal_Loan</th>\n",
       "      <th>Loan_Debt_Consolidation_Loan</th>\n",
       "      <th>Loan_Mortgage_Loan</th>\n",
       "      <th>Loan_Student_Loan</th>\n",
       "      <th>Loan_Credit-Builder_Loan</th>\n",
       "      <th>Loan_Auto_Loan</th>\n",
       "      <th>Loan_Not_Specified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0x2ff7</td>\n",
       "      <td>-0.231084</td>\n",
       "      <td>-1.154507</td>\n",
       "      <td>1.226085</td>\n",
       "      <td>-0.360448</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>0.563097</td>\n",
       "      <td>-1.588400</td>\n",
       "      <td>1.262261</td>\n",
       "      <td>-1.177340</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0x303a</td>\n",
       "      <td>-1.036914</td>\n",
       "      <td>1.796077</td>\n",
       "      <td>-0.126767</td>\n",
       "      <td>0.758165</td>\n",
       "      <td>0.620311</td>\n",
       "      <td>-0.791628</td>\n",
       "      <td>-0.921110</td>\n",
       "      <td>0.762157</td>\n",
       "      <td>-0.058155</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0x305c</td>\n",
       "      <td>-0.221136</td>\n",
       "      <td>-1.144437</td>\n",
       "      <td>1.453207</td>\n",
       "      <td>-0.570188</td>\n",
       "      <td>0.303238</td>\n",
       "      <td>-1.048729</td>\n",
       "      <td>-0.702000</td>\n",
       "      <td>-0.178038</td>\n",
       "      <td>-1.098106</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0x3082</td>\n",
       "      <td>0.853304</td>\n",
       "      <td>0.094204</td>\n",
       "      <td>-0.610634</td>\n",
       "      <td>-2.068330</td>\n",
       "      <td>0.600494</td>\n",
       "      <td>-1.740924</td>\n",
       "      <td>0.094763</td>\n",
       "      <td>-1.208251</td>\n",
       "      <td>-0.177007</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0x308d</td>\n",
       "      <td>-0.519591</td>\n",
       "      <td>-0.238114</td>\n",
       "      <td>2.588813</td>\n",
       "      <td>-0.280547</td>\n",
       "      <td>-0.846151</td>\n",
       "      <td>-1.721147</td>\n",
       "      <td>0.274035</td>\n",
       "      <td>-0.998208</td>\n",
       "      <td>-0.186911</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer_ID      fe_1      fe_2      fe_3      fe_4      fe_5      fe_6  \\\n",
       "0  CUS_0x2ff7 -0.231084 -1.154507  1.226085 -0.360448  0.025799  0.563097   \n",
       "1  CUS_0x303a -1.036914  1.796077 -0.126767  0.758165  0.620311 -0.791628   \n",
       "2  CUS_0x305c -0.221136 -1.144437  1.453207 -0.570188  0.303238 -1.048729   \n",
       "3  CUS_0x3082  0.853304  0.094204 -0.610634 -2.068330  0.600494 -1.740924   \n",
       "4  CUS_0x308d -0.519591 -0.238114  2.588813 -0.280547 -0.846151 -1.721147   \n",
       "\n",
       "       fe_7      fe_8      fe_9  ...  Credit_Mix_Standard  \\\n",
       "0 -1.588400  1.262261 -1.177340  ...                    1   \n",
       "1 -0.921110  0.762157 -0.058155  ...                    0   \n",
       "2 -0.702000 -0.178038 -1.098106  ...                    1   \n",
       "3  0.094763 -1.208251 -0.177007  ...                    1   \n",
       "4  0.274035 -0.998208 -0.186911  ...                    0   \n",
       "\n",
       "   Loan_Home_Equity_Loan  Loan_Payday_Loan  Loan_Personal_Loan  \\\n",
       "0                      1                 1                   0   \n",
       "1                      1                 1                   0   \n",
       "2                      0                 0                   1   \n",
       "3                      0                 1                   0   \n",
       "4                      0                 0                   0   \n",
       "\n",
       "   Loan_Debt_Consolidation_Loan  Loan_Mortgage_Loan  Loan_Student_Loan  \\\n",
       "0                             0                   1                  0   \n",
       "1                             0                   0                  0   \n",
       "2                             0                   0                  1   \n",
       "3                             0                   0                  0   \n",
       "4                             0                   0                  0   \n",
       "\n",
       "   Loan_Credit-Builder_Loan  Loan_Auto_Loan  Loan_Not_Specified  \n",
       "0                         1               0                   0  \n",
       "1                         1               0                   0  \n",
       "2                         0               0                   0  \n",
       "3                         1               0                   1  \n",
       "4                         0               0                   1  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load gold feature store for the inference date\n",
    "gold_feature_store_path = \"datamart/gold/feature_store/\"\n",
    "files_list = [os.path.join(gold_feature_store_path, os.path.basename(f)) for f in glob.glob(os.path.join(gold_feature_store_path, '*'))]\n",
    "features_store_sdf = spark.read.option(\"header\", \"true\").parquet(*files_list)\n",
    "features_sdf = features_store_sdf.filter(col(\"snapshot_date\") == config[\"snapshot_date\"])\n",
    "features_pdf = features_sdf.toPandas()\n",
    "\n",
    "features_pdf.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b87df3-15a4-4132-9ffe-112d9a1c643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-feature columns to get only feature columns\n",
    "non_feature_cols = [\n",
    "    'Customer_ID',\n",
    "    'clickstream_snapshot_date',\n",
    "    'attributes_snapshot_date',\n",
    "    'financial_snapshot_date',\n",
    "    'snapshot_date'\n",
    "]\n",
    "\n",
    "X_inference = features_pdf.drop(columns=non_feature_cols).values  # Convert to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f361665-930e-47ec-b312-679ecd40cb2e",
   "metadata": {},
   "source": [
    "## preprocess data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04410356-646a-41d6-8f1e-8876f0f4f147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Apply the scaler\n",
    "transformer_stdscaler = model_artefact[\"preprocessing_transformers\"][\"stdscaler\"]\n",
    "X_inference = transformer_stdscaler.transform(X_inference)\n",
    "\n",
    "print('X_inference', X_inference.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a4362f-9dee-4838-a030-a74b88884b4f",
   "metadata": {},
   "source": [
    "## model prediction inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5e85498-68bb-4083-8035-3247d7e296d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0x2ff7</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>credit_model_2024_09_02.pkl</td>\n",
       "      <td>0.414623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0x303a</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>credit_model_2024_09_02.pkl</td>\n",
       "      <td>0.401065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0x305c</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>credit_model_2024_09_02.pkl</td>\n",
       "      <td>0.462319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0x3082</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>credit_model_2024_09_02.pkl</td>\n",
       "      <td>0.563414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0x308d</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>credit_model_2024_09_02.pkl</td>\n",
       "      <td>0.416237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>CUS_0x2e1a</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>credit_model_2024_09_02.pkl</td>\n",
       "      <td>0.465596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>CUS_0x2e8d</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>credit_model_2024_09_02.pkl</td>\n",
       "      <td>0.398042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>CUS_0x2ee4</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>credit_model_2024_09_02.pkl</td>\n",
       "      <td>0.462323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>CUS_0x2fa7</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>credit_model_2024_09_02.pkl</td>\n",
       "      <td>0.590299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>CUS_0x2fc5</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>credit_model_2024_09_02.pkl</td>\n",
       "      <td>0.527112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>485 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Customer_ID snapshot_date                   model_name  model_predictions\n",
       "0    CUS_0x2ff7    2024-01-01  credit_model_2024_09_02.pkl           0.414623\n",
       "1    CUS_0x303a    2024-01-01  credit_model_2024_09_02.pkl           0.401065\n",
       "2    CUS_0x305c    2024-01-01  credit_model_2024_09_02.pkl           0.462319\n",
       "3    CUS_0x3082    2024-01-01  credit_model_2024_09_02.pkl           0.563414\n",
       "4    CUS_0x308d    2024-01-01  credit_model_2024_09_02.pkl           0.416237\n",
       "..          ...           ...                          ...                ...\n",
       "480  CUS_0x2e1a    2024-01-01  credit_model_2024_09_02.pkl           0.465596\n",
       "481  CUS_0x2e8d    2024-01-01  credit_model_2024_09_02.pkl           0.398042\n",
       "482  CUS_0x2ee4    2024-01-01  credit_model_2024_09_02.pkl           0.462323\n",
       "483  CUS_0x2fa7    2024-01-01  credit_model_2024_09_02.pkl           0.590299\n",
       "484  CUS_0x2fc5    2024-01-01  credit_model_2024_09_02.pkl           0.527112\n",
       "\n",
       "[485 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = model_artefact[\"model\"]\n",
    "\n",
    "# predict model\n",
    "y_inference = model.predict_proba(X_inference)[:, 1]\n",
    "\n",
    "# prepare output\n",
    "y_inference_pdf = features_pdf[[\"Customer_ID\",\"snapshot_date\"]].copy()\n",
    "y_inference_pdf[\"model_name\"] = config[\"model_name\"]\n",
    "y_inference_pdf[\"model_predictions\"] = y_inference\n",
    "y_inference_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3fe2b8-4642-486d-aa3b-2d7703ad3d15",
   "metadata": {},
   "source": [
    "## save model inference to datamart gold table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c28e3e5-81ca-4685-a1f1-f1df12908a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2024_01_01.parquet\n"
     ]
    }
   ],
   "source": [
    "# create bronze datalake\n",
    "gold_directory = f\"datamart/gold/model_predictions/{config['model_name'][:-4]}/\"\n",
    "print(gold_directory)\n",
    "\n",
    "if not os.path.exists(gold_directory):\n",
    "    os.makedirs(gold_directory)\n",
    "\n",
    "# save gold table - IRL connect to database to write\n",
    "partition_name = config[\"model_name\"][:-4] + \"_predictions_\" + snapshot_date_str.replace('-','_') + '.parquet'\n",
    "filepath = gold_directory + partition_name\n",
    "spark.createDataFrame(y_inference_pdf).write.mode(\"overwrite\").parquet(filepath)\n",
    "\n",
    "print('saved to:', filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0dfb6-dc32-4a70-9118-9d924213fb2c",
   "metadata": {},
   "source": [
    "## backfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4a8f65f-d5d1-45cf-8eaa-bd9c54991a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up config\n",
    "snapshot_date_str = \"2023-02-01\"\n",
    "\n",
    "start_date_str = \"2023-02-01\"\n",
    "end_date_str = \"2024-12-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "849e738c-c717-400f-b72d-ba9951866ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of dates to process\n",
    "def generate_first_of_month_dates(start_date_str, end_date_str):\n",
    "    # Convert the date strings to datetime objects\n",
    "    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    # List to store the first of month dates\n",
    "    first_of_month_dates = []\n",
    "\n",
    "    # Start from the first of the month of the start_date\n",
    "    current_date = datetime(start_date.year, start_date.month, 1)\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        # Append the date in yyyy-mm-dd format\n",
    "        first_of_month_dates.append(current_date.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        # Move to the first of the next month\n",
    "        if current_date.month == 12:\n",
    "            current_date = datetime(current_date.year + 1, 1, 1)\n",
    "        else:\n",
    "            current_date = datetime(current_date.year, current_date.month + 1, 1)\n",
    "\n",
    "    return first_of_month_dates\n",
    "\n",
    "dates_str_lst = generate_first_of_month_dates(start_date_str, end_date_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93576148-36ca-4571-b327-2317f9656cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 2, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-02-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 501 2023-02-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 501\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2023_02_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-03-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 3, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-03-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 506 2023-03-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 506\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2023_03_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-04-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 4, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-04-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 510 2023-04-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 510\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2023_04_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-05-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 5, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-05-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 521 2023-05-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 521\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2023_05_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-06-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 6, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-06-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 517 2023-06-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 517\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2023_06_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-07-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 7, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-07-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 471 2023-07-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 471\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2023_07_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-08-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 8, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-08-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 481 2023-08-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 481\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2023_08_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-09-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 9, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-09-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 454 2023-09-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 454\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2023_09_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-10-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 10, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-10-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 487 2023-10-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 487\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2023_10_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-11-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 11, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-11-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 491 2023-11-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 491\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2023_11_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-12-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 12, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-12-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 489 2023-12-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 489\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2023_12_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-01-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 1, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-01-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 485 2024-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 485\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2024_01_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-02-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 2, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-02-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 518 2024-02-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 518\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2024_02_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-03-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 3, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-03-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 511 2024-03-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 511\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2024_03_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-04-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 4, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-04-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 513 2024-04-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 513\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2024_04_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-05-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 5, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-05-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 491 2024-05-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 491\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2024_05_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-06-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 6, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-06-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 498 2024-06-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 498\n",
      "datamart/gold/model_predictions/credit_model_2024_09_02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_02/credit_model_2024_09_02_predictions_2024_06_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-07-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_02.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_02.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 7, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-07-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_02.pkl\n",
      "extracted features_sdf 0 2024-07-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 34)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m label_files = glob.glob(os.path.join(label_dir, \u001b[33m\"\u001b[39m\u001b[33m*.parquet\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label_files:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mmodel_inference\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnapshot_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLabel file missing for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msnapshot_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, skipping.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/model_inference.py:58\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(snapshotdate, modelname)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Apply the scaler\u001b[39;00m\n\u001b[32m     57\u001b[39m transformer_stdscaler = model_artefact[\u001b[33m\"\u001b[39m\u001b[33mpreprocessing_transformers\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mstdscaler\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m X_inference = \u001b[43mtransformer_stdscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_inference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mX_inference\u001b[39m\u001b[33m'\u001b[39m, X_inference.shape[\u001b[32m0\u001b[39m])\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# --- model prediction inference ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/sklearn/utils/_set_output.py:157\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    160\u001b[39m         return_tuple = (\n\u001b[32m    161\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    162\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    163\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:1006\u001b[39m, in \u001b[36mStandardScaler.transform\u001b[39m\u001b[34m(self, X, copy)\u001b[39m\n\u001b[32m   1003\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1005\u001b[39m copy = copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparse.issparse(X):\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.with_mean:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:605\u001b[39m, in \u001b[36mBaseEstimator._validate_data\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[39m\n\u001b[32m    603\u001b[39m         out = X, y\n\u001b[32m    604\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m    607\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/sklearn/utils/validation.py:967\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m    965\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    968\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    969\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    970\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m    971\u001b[39m         )\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m    974\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 34)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "dates_str_lst = generate_first_of_month_dates(start_date_str, end_date_str)\n",
    "\n",
    "for snapshot_date in dates_str_lst:\n",
    "    print(snapshot_date)\n",
    "    # Build the directory path for this date\n",
    "    label_dir = f\"datamart/gold/label_store/gold_label_store_{snapshot_date.replace('-', '_')}.parquet\"\n",
    "    # Find all parquet files inside the directory\n",
    "    label_files = glob.glob(os.path.join(label_dir, \"*.parquet\"))\n",
    "    if label_files:\n",
    "        model_inference.main(snapshot_date, model_name)\n",
    "    else:\n",
    "        print(f\"Label file missing for {snapshot_date}, skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339e3cb-1826-49a0-ac73-cb381f85b033",
   "metadata": {},
   "source": [
    "## Check datamart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef4abd-3e08-4430-9fc5-d9eb2d0bba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dff83cf-fcc1-4a4c-919a-c2c4be859f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"datamart/gold/model_predictions/credit_model_2024_09_02/\"\n",
    "files_list = [folder_path+os.path.basename(f) for f in glob.glob(os.path.join(folder_path, '*'))]\n",
    "df = spark.read.option(\"header\", \"true\").parquet(*files_list)\n",
    "print(\"row_count:\",df.count())\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cfdbc-cb22-4a36-a51c-627108f20592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
